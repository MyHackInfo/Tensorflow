{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction To Neural Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyHackInfo/Tensorflow/blob/master/Introduction_To_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "f3EeIJirvPrw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Perceptron Model Mathematically:\n",
        "  per> result, \n",
        "  w> weight,\n",
        "  x> input ,\n",
        "  b> Bias,\n",
        "  \n",
        "  per = w * x + b\n",
        "  \n",
        "  [Artificial Neural Networks](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwj9hfqO2OLgAhVDL48KHY7DCVYQjRx6BAgBEAU&url=https%3A%2F%2Ftowardsdatascience.com%2Fapplied-deep-learning-part-1-artificial-neural-networks-d7834f67a4f6&psig=AOvVaw3MXISsvtNceYFUrIFvs49a&ust=1551589678464024)\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "mLwM0_tf0Rgf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [Activation Function:-](https://www.geeksforgeeks.org/activation-functions-neural-networks/)\n",
        "Activation function decides, whether a neuron should be activated or not by calculating weighted sum and further adding bias with it. The purpose of the activation function is to introduce non-linearity into the output of a neuron\n",
        "1.   [Threshold Function](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwjB7cb12eLgAhUDS48KHbTIBHQQjRx6BAgBEAU&url=https%3A%2F%2Fwww.superdatascience.com%2Fartificial-neural-networks-the-activation-function%2F&psig=AOvVaw13sJvrhIDAsGnb-DtJD3LC&ust=1551590108171466)\n",
        "2.  [Sigmoid Function](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwj-6daZ2uLgAhXGknAKHZTDBfoQjRx6BAgBEAU&url=https%3A%2F%2Ftowardsdatascience.com%2Factivation-functions-neural-networks-1cbd9f8d91d6&psig=AOvVaw1ERIPgEGxWac59TLvScmsc&ust=1551590235071327)\n",
        "3.  [Rectifier Function](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwjMmKiv2uLgAhWJLY8KHeYRAu0QjRx6BAgBEAU&url=https%3A%2F%2Fmedium.com%2F%40kanchansarkar%2Frelu-not-a-differentiable-function-why-used-in-gradient-based-optimization-7fef3a4cecec&psig=AOvVaw1W8dlb1W8JpFTy5L9wwOiZ&ust=1551590271232363)\n",
        "4.  [ Hyperbolic Tangent(tanh) Function](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwintMec2-LgAhVDwI8KHerdDnEQjRx6BAgBEAU&url=http%3A%2F%2Fmathworld.wolfram.com%2FHyperbolicTangent.html&psig=AOvVaw19cep9jLUrqpNuhEACZOvC&ust=1551590303899189)\n",
        "[link text](https://www.geeksforgeeks.org/activation-functions-neural-networks/)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2LyROW5_Cj53",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  [Cost Functions:-](https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications)\n",
        "A cost function is a measure of \"how good\" a neural network did with respect to it's given training sample and the expected output. It also may depend on variables such as weights and biases\n",
        "\n",
        "\n",
        "1.   [Quadratic cost](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwiA-OjB6eLgAhUlTY8KHXVxCCYQjRx6BAgBEAU&url=https%3A%2F%2Fslideplayer.com%2Fslide%2F9079137%2F&psig=AOvVaw3rNmnBmzuqR5uwiryIA6Op&ust=1551594292761080)\n",
        "2.   [Cross-entropy cost](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwjm_ujm6eLgAhVNinAKHRCXBEsQjRx6BAgBEAU&url=https%3A%2F%2Fwww.slideshare.net%2Fssusereab2f3%2Fmultinomial-classification-amp-application-of-ml&psig=AOvVaw1lL3bNJfSb2b0pkT0wDAWA&ust=1551594405995621)\n",
        "3.   [Exponentional cost](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwjH_dyp6uLgAhUEiXAKHdiJCFYQjRx6BAgBEAU&url=https%3A%2F%2Fwww.slideshare.net%2Ffuglylogic%2Fmicroservices-26369481&psig=AOvVaw0sbf1TXdWvQ9MwwjjyKjxD&ust=1551594486048695)\n"
      ]
    },
    {
      "metadata": {
        "id": "ua3KGfrELj_k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [Gradient Descent:-](https://www.analyticsvidhya.com/blog/2017/03/introduction-to-gradient-descent-algorithm-along-its-variants/)\n",
        "Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model. Parameters refer to coefficients in Linear Regression and weights in neural networks.\n"
      ]
    },
    {
      "metadata": {
        "id": "6hMleWwGN_N4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [Backpropagation:-](https://www.edureka.co/blog/backpropagation/)\n",
        "Basically, what we need to do, we need to somehow explain the model to change the parameters (weights), such that error becomes minimum.\n",
        "Letâ€™s put it in an another way, we need to train our model.\n",
        "One way to train our model is called as Backpropagation"
      ]
    },
    {
      "metadata": {
        "id": "zj6kIy1EOOUt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wRsGuA9WS8bg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [A Neural Network Playground](https://playground.tensorflow.org)"
      ]
    },
    {
      "metadata": {
        "id": "UBCvc_KzTEnk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}